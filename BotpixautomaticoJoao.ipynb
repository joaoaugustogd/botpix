{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrP/svY47jjp4g+K6bU44F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaoaugustogd/botpix/blob/main/BotpixautomaticoJoao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar Framework de agentes do Google ################################################\n",
        "!pip install -q google-adk"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GRR72NliNEoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "import re # Importar o módulo re para a Agente 2\n",
        "\n",
        "\n",
        "# Configure sua chave de API (certifique-se de que está correta)\n",
        "os.environ.get(\"GOOGLE_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "collapsed": true,
        "id": "B7-fOE_BRMTE",
        "outputId": "b125f7b8-5fa7-4d1e-c05d-beb9e8508f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AIzaSyBUhtWn65oJHF4Q7k7B9QBTIhuJvIIwNHw'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=\"AIzaSyBUhtWn65oJHF4Q7k7B9QBTIhuJvIIwNHw\")\n"
      ],
      "metadata": {
        "id": "T52dfRNCTmnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "MbOZRYv8Mfy4",
        "outputId": "11247282-1e00-4a3c-a2ea-898fbd5e6333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelos disponíveis e métodos suportados:\n",
            "Nome do Modelo: models/embedding-gecko-001\n",
            "Descrição: Obtain a distributed representation of a text.\n",
            "Métodos suportados: ['embedText', 'countTextTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-1.0-pro-vision-latest\n",
            "Descrição: The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.\n",
            "Métodos suportados: ['generateContent', 'countTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-pro-vision\n",
            "Descrição: The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.\n",
            "Métodos suportados: ['generateContent', 'countTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-1.5-pro-latest\n",
            "Descrição: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.\n",
            "Métodos suportados: ['generateContent', 'countTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-1.5-pro-001\n",
            "Descrição: Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-1.5-pro-002\n",
            "Descrição: Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-1.5-pro\n",
            "Descrição: Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.\n",
            "Métodos suportados: ['generateContent', 'countTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-1.5-flash-latest\n",
            "Descrição: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.\n",
            "Métodos suportados: ['generateContent', 'countTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-1.5-flash-001\n",
            "Descrição: Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-1.5-flash-001-tuning\n",
            "Descrição: Version of Gemini 1.5 Flash that supports tuning, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createTunedModel']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-1.5-flash\n",
            "Descrição: Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.\n",
            "Métodos suportados: ['generateContent', 'countTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-1.5-flash-002\n",
            "Descrição: Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-1.5-flash-8b\n",
            "Descrição: Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
            "Métodos suportados: ['createCachedContent', 'generateContent', 'countTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-1.5-flash-8b-001\n",
            "Descrição: Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
            "Métodos suportados: ['createCachedContent', 'generateContent', 'countTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-1.5-flash-8b-latest\n",
            "Descrição: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
            "Métodos suportados: ['createCachedContent', 'generateContent', 'countTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-1.5-flash-8b-exp-0827\n",
            "Descrição: Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).\n",
            "Métodos suportados: ['generateContent', 'countTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-1.5-flash-8b-exp-0924\n",
            "Descrição: Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).\n",
            "Métodos suportados: ['generateContent', 'countTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.5-pro-exp-03-25\n",
            "Descrição: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.5-pro-preview-03-25\n",
            "Descrição: Gemini 2.5 Pro Preview 03-25\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.5-flash-preview-04-17\n",
            "Descrição: Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.5-flash-preview-04-17-thinking\n",
            "Descrição: Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.5-pro-preview-05-06\n",
            "Descrição: Preview release (May 6th, 2025) of Gemini 2.5 Pro\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.0-flash-exp\n",
            "Descrição: Gemini 2.0 Flash Experimental\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.0-flash\n",
            "Descrição: Gemini 2.0 Flash\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.0-flash-001\n",
            "Descrição: Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.0-flash-exp-image-generation\n",
            "Descrição: Gemini 2.0 Flash (Image Generation) Experimental\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.0-flash-lite-001\n",
            "Descrição: Stable version of Gemini 2.0 Flash Lite\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.0-flash-lite\n",
            "Descrição: Gemini 2.0 Flash-Lite\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.0-flash-preview-image-generation\n",
            "Descrição: Gemini 2.0 Flash Preview Image Generation\n",
            "Métodos suportados: ['generateContent', 'countTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.0-flash-lite-preview-02-05\n",
            "Descrição: Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.0-flash-lite-preview\n",
            "Descrição: Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.0-pro-exp\n",
            "Descrição: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.0-pro-exp-02-05\n",
            "Descrição: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-exp-1206\n",
            "Descrição: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.0-flash-thinking-exp-01-21\n",
            "Descrição: Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.0-flash-thinking-exp\n",
            "Descrição: Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.0-flash-thinking-exp-1219\n",
            "Descrição: Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
            "Métodos suportados: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/learnlm-2.0-flash-experimental\n",
            "Descrição: LearnLM 2.0 Flash Experimental\n",
            "Métodos suportados: ['generateContent', 'countTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemma-3-1b-it\n",
            "Descrição: \n",
            "Métodos suportados: ['generateContent', 'countTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemma-3-4b-it\n",
            "Descrição: \n",
            "Métodos suportados: ['generateContent', 'countTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemma-3-12b-it\n",
            "Descrição: \n",
            "Métodos suportados: ['generateContent', 'countTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemma-3-27b-it\n",
            "Descrição: \n",
            "Métodos suportados: ['generateContent', 'countTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/embedding-001\n",
            "Descrição: Obtain a distributed representation of a text.\n",
            "Métodos suportados: ['embedContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/text-embedding-004\n",
            "Descrição: Obtain a distributed representation of a text.\n",
            "Métodos suportados: ['embedContent']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-embedding-exp-03-07\n",
            "Descrição: Obtain a distributed representation of a text.\n",
            "Métodos suportados: ['embedContent', 'countTextTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-embedding-exp\n",
            "Descrição: Obtain a distributed representation of a text.\n",
            "Métodos suportados: ['embedContent', 'countTextTokens']\n",
            "------------------------------\n",
            "Nome do Modelo: models/aqa\n",
            "Descrição: Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.\n",
            "Métodos suportados: ['generateAnswer']\n",
            "------------------------------\n",
            "Nome do Modelo: models/imagen-3.0-generate-002\n",
            "Descrição: Vertex served Imagen 3.0 002 model\n",
            "Métodos suportados: ['predict']\n",
            "------------------------------\n",
            "Nome do Modelo: models/gemini-2.0-flash-live-001\n",
            "Descrição: Gemini 2.0 Flash 001\n",
            "Métodos suportados: ['bidiGenerateContent', 'countTokens']\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "#1\n",
        "\n",
        "# Listar modelos disponíveis\n",
        "print(\"Modelos disponíveis e métodos suportados:\")\n",
        "for model in genai.list_models():\n",
        "    print(f\"Nome do Modelo: {model.name}\")\n",
        "    print(f\"Descrição: {model.description}\")\n",
        "    print(f\"Métodos suportados: {model.supported_generation_methods}\")\n",
        "    print(\"-\" * 30)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    gemini_model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "    print(\"\\nModelo Gemini 'gemini-1.5-flash-latest' configurado com sucesso.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nErro ao configurar o modelo Gemini: {e}\")\n",
        "    print(\"Verifique a lista de modelos disponíveis acima e escolha um modelo válido para 'generateContent'.\")\n",
        "    gemini_model = None # Define como None se a configuração falhar\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWuuEvaFTAS3",
        "outputId": "3276208e-a467-4f0b-89f5-ebf32bc31e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modelo Gemini 'gemini-1.5-flash-latest' configurado com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "class PaymentInquiryIntentAgentGemini:\n",
        "    def identify_intent(self, user_message):\n",
        "        prompt = f\"\"\"Identifique a intenção principal do seguinte texto: \"{user_message}\".\n",
        "        A intenção deve ser uma das seguintes categorias:\n",
        "        - ENTENDER_PIX_AUTOMATICO\n",
        "        - COMO_CADASTRAR_PIX\n",
        "        - COMO_AGENDAR_PIX\n",
        "        - CONSULTAR_AGENDAMENTOS_PIX\n",
        "        - CANCELAR_AGENDAMENTO_PIX\n",
        "        - PROBLEMA_PAGAMENTO\n",
        "        - LIMITES_PIX_AUTOMATICO\n",
        "        - REGRAS_PIX_AUTOMATICO\n",
        "        - DUVIDA_OUTROS_PAGAMENTOS\n",
        "        - NAO_RECONHECIDA\n",
        "        Retorne apenas o nome da categoria da intenção.\"\"\"\n",
        "        try:\n",
        "            response = gemini_model.generate_content(prompt)\n",
        "            return response.text.strip()\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao identificar intenção com Gemini: {e}\")\n",
        "            return \"NAO_RECONHECIDA\"\n",
        "\n",
        "def agente_intencao_pagamentos_gemini(mensagem_usuario):\n",
        "    agente = PaymentInquiryIntentAgentGemini()\n",
        "    intencao = agente.identify_intent(mensagem_usuario)\n",
        "    return intencao"
      ],
      "metadata": {
        "id": "nFG2ljoFMgaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "class PaymentEntityExtractionAgent:\n",
        "    def extract_entities(self, user_message, intent):\n",
        "        entities = {}\n",
        "        user_message = user_message.lower()\n",
        "\n",
        "        if intent in [\"ENTENDER_PIX_AUTOMATICO\", \"COMO_CADASTRAR_PIX\", \"COMO_AGENDAR_PIX\", \"CANCELAR_AGENDAMENTO_PIX\"]:\n",
        "            beneficiario_match = re.search(r\"(?:para|de)\\s*(a|o|os|as)\\s*(.*?)(?:,|\\s|$|\\.)\", user_message)\n",
        "            if beneficiario_match:\n",
        "                entities[\"beneficiario\"] = beneficiario_match.group(2).strip()\n",
        "            conta_match = re.search(r\"(?:conta|para)\\s*(.*?)(?:,|\\s|$|\\.)\", user_message)\n",
        "            if conta_match and \"beneficiario\" not in entities:\n",
        "                entities[\"conta\"] = conta_match.group(1).strip()\n",
        "            valor_match = re.search(r\"(?:valor|de)\\s*(r\\$?\\s*[\\d.,]+)\", user_message)\n",
        "            if valor_match:\n",
        "                try:\n",
        "                    entities[\"valor\"] = float(valor_match.group(1).replace(\"r$\", \"\").replace(\" \", \"\").replace(\",\", \".\"))\n",
        "                except ValueError:\n",
        "                    pass\n",
        "            data_match = re.search(r\"(?:para|em)\\s*([\\d/.-]+)\", user_message)\n",
        "            if data_match:\n",
        "                entities[\"data\"] = data_match.group(1).strip()\n",
        "\n",
        "        elif intent == \"PROBLEMA_PAGAMENTO\":\n",
        "            tipo_pagamento_match = re.search(r\"(pix automático|pix|boleto|transferência)\", user_message)\n",
        "            if tipo_pagamento_match:\n",
        "                entities[\"tipo_pagamento\"] = tipo_pagamento_match.group(1)\n",
        "            id_match = re.search(r\"(id|código)\\s*(?:de)?\\s*([\\w-]+)\", user_message)\n",
        "            if id_match:\n",
        "                entities[\"id_transacao\"] = id_match.group(2)\n",
        "\n",
        "        return entities\n",
        "\n",
        "def agente_extrator_entidades_pagamentos(mensagem_usuario, intencao):\n",
        "    agente = PaymentEntityExtractionAgent()\n",
        "    entidades = agente.extract_entities(mensagem_usuario, intencao)\n",
        "    return entidades\n"
      ],
      "metadata": {
        "id": "dVD0nhM4QWUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "#4\n",
        "class PaymentInfoResponseAgentGemini:\n",
        "    def generate_response(self, intent, entities=None):\n",
        "        prompt = \"\"\n",
        "        if intent == \"ENTENDER_PIX_AUTOMATICO\":\n",
        "            prompt = \"Explique o que é o Pix automático de forma clara e concisa.\"\n",
        "        elif intent == \"COMO_CADASTRAR_PIX\":\n",
        "            beneficiario = entities.get(\"beneficiario\", \"o beneficiário\")\n",
        "            prompt = f\"Como posso cadastrar o Pix automático para {beneficiario}? Forneça um guia passo a passo geral.\"\n",
        "        elif intent == \"COMO_AGENDAR_PIX\":\n",
        "            beneficiario = entities.get(\"beneficiario\", \"o beneficiário\")\n",
        "            data = entities.get(\"data\", \"uma data específica\")\n",
        "            valor = entities.get(\"valor\", \"um valor\")\n",
        "            prompt = f\"Como posso agendar um Pix automático para {beneficiario}? Forneça um guia passo a passo geral.\"\n",
        "\n",
        "\n",
        "            # Check if valor is a number before formatting\n",
        "            if isinstance(valor, (int, float)):\n",
        "                valor_str = f\"R$ {valor:.2f}\"\n",
        "            else:\n",
        "                valor_str = str(valor) # Use the default string if not a number\n",
        "\n",
        "            prompt = f\"Como agendo um pagamento via Pix para {beneficiario} no valor de {valor_str} para {data}? Explique o processo.\"\n",
        "        elif intent == \"CONSULTAR_AGENDAMENTOS_PIX\":\n",
        "            prompt = \"Como consulto meus pagamentos agendados via Pix?\"\n",
        "        elif intent == \"CANCELAR_AGENDAMENTO_PIX\":\n",
        "            beneficiario = entities.get(\"beneficiario\", \"um agendamento\")\n",
        "            prompt = f\"Como cancelo um agendamento de Pix para {beneficiario}?\"\n",
        "        elif intent == \"PROBLEMA_PAGAMENTO\":\n",
        "            tipo = entities.get(\"tipo_pagamento\", \"um pagamento\")\n",
        "            id_transacao = entities.get(\"id_transacao\", \"esta transação\")\n",
        "            prompt = f\"Tive um problema com {tipo} (ID: {id_transacao}). Quais são os passos gerais para solucionar isso?\"\n",
        "        elif intent == \"LIMITES_PIX_AUTOMATICO\":\n",
        "            prompt = \"Quais são os limites para o Pix automático?\"\n",
        "        elif intent == \"REGRAS_PIX_AUTOMATICO\":\n",
        "            prompt = \"Quais são as regras gerais do Pix automático?\"\n",
        "        elif intent == \"DUVIDA_OUTROS_PAGAMENTOS\":\n",
        "            prompt = \"O usuário tem uma dúvida sobre outros pagamentos (boleto, transferência, etc.). Peça mais detalhes para poder ajudar.\"\n",
        "        elif intent == \"NAO_RECONHECIDA\":\n",
        "            return \"Desculpe, não consegui entender sua pergunta sobre pagamentos. Por favor, tente reformular.\"\n",
        "        else:\n",
        "            return \"Não tenho uma resposta clara para essa pergunta no momento.\"\n",
        "\n",
        "        try:\n",
        "            response = gemini_model.generate_content(prompt)\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao gerar resposta com Gemini: {e}\")\n",
        "            return \"Ocorreu um erro ao processar sua solicitação.\"\n",
        "\n",
        "def agente_resposta_pagamentos_gemini(intencao, entidades=None):\n",
        "    agente = PaymentInfoResponseAgentGemini()\n",
        "    resposta = agente.generate_response(intencao, entidades)\n",
        "    return resposta\n"
      ],
      "metadata": {
        "id": "BLY14sueQZWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5\n",
        "def chatbot_pagamentos_gemini(mensagem_usuario):\n",
        "    # Agente 1 (Gemini): Identifica a Intenção\n",
        "    intencao = agente_intencao_pagamentos_gemini(mensagem_usuario)\n",
        "    print(f\"Intenção identificada (Gemini): {intencao}\")\n",
        "\n",
        "    # Agente 2: Extrai Entidades (Lógica baseada em regras mantida)\n",
        "    entidades = agente_extrator_entidades_pagamentos(mensagem_usuario, intencao)\n",
        "    print(f\"Entidades extraídas: {entidades}\")\n",
        "\n",
        "    # Agente 3 & 4 (Gemini): Gera a Resposta\n",
        "    resposta = agente_resposta_pagamentos_gemini(intencao, entidades)\n",
        "    print(f\"Resposta do chatbot (Gemini): {resposta}\")\n",
        "\n",
        "    return resposta"
      ],
      "metadata": {
        "id": "BoCWO6j1QcIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Olá! Como posso te ajudar com Pix automático e pagamentos?\")\n",
        "    while True:\n",
        "        mensagem = input(\"Você: \")\n",
        "        if mensagem.lower() in [\"sair\", \"encerrar\", \"adeus\", \"valeu\", \"falous\",]:\n",
        "            print(\"Até a próxima!\")\n",
        "            break\n",
        "        resposta_chatbot = chatbot_pagamentos_gemini(mensagem)\n",
        "        print(f\"Chatbot: {resposta_chatbot}\")\n"
      ],
      "metadata": {
        "id": "N9_XYVhYQtmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-generativeai gradio\n",
        "\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import re # Importar o módulo re para a Agente 2\n",
        "\n",
        "\n",
        "# Configure sua chave de API (certifique-se de que está correta)\n",
        "os.environ.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "model = genai.GenerativeModel(\"models/gemini-1.5-pro-latest\")\n",
        "\n",
        "def responder(pergunta):\n",
        "    try:\n",
        "        resposta = model.generate_content(pergunta, generation_config={\"max_output_tokens\": 200})\n",
        "        return resposta.text\n",
        "    except Exception as e:\n",
        "        return f\"Erro: {str(e)}\"\n",
        "\n",
        "gr.Interface(\n",
        "    fn=responder,\n",
        "    inputs=gr.Textbox(lines=3, label=\"Mensagem\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"BotPix com Gemini\",\n",
        ").launch(share=True)\n"
      ],
      "metadata": {
        "id": "LF5JgLYEQw4E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "1b22e936-7162-4f6e-e44c-186f263bb60e"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://921350a83376c24d4b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://921350a83376c24d4b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2zb5Qq3VqBtt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}